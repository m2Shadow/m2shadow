<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>朴素贝叶斯 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="公式P(Y|X) = P(X|Y)P(Y)/P(X) P(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y) P(&amp;apos;属于某类&amp;apos; | &amp;apos;具有某特征&amp;apos;) 只需要找到一些包含已知特征标签的样本，即可训练。 思想贝叶斯的核心思想：高概率对应的类别。 如果    P(‘属于A类’| ‘具有某特征’) &amp;gt; P(‘属于B类’| ‘具有某特征’)，那么(x,">
<meta name="keywords" content="naive bayes">
<meta property="og:type" content="article">
<meta property="og:title" content="朴素贝叶斯">
<meta property="og:url" content="http://yoursite.com/2017/07/26/朴素贝叶斯/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="公式P(Y|X) = P(X|Y)P(Y)/P(X) P(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y) P(&amp;apos;属于某类&amp;apos; | &amp;apos;具有某特征&amp;apos;) 只需要找到一些包含已知特征标签的样本，即可训练。 思想贝叶斯的核心思想：高概率对应的类别。 如果    P(‘属于A类’| ‘具有某特征’) &amp;gt; P(‘属于B类’| ‘具有某特征’)，那么(x,">
<meta property="og:updated_time" content="2017-07-27T13:31:21.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="朴素贝叶斯">
<meta name="twitter:description" content="公式P(Y|X) = P(X|Y)P(Y)/P(X) P(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y) P(&amp;apos;属于某类&amp;apos; | &amp;apos;具有某特征&amp;apos;) 只需要找到一些包含已知特征标签的样本，即可训练。 思想贝叶斯的核心思想：高概率对应的类别。 如果    P(‘属于A类’| ‘具有某特征’) &amp;gt; P(‘属于B类’| ‘具有某特征’)，那么(x,">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-66782234-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="https://github.com/pangrou">GitHub</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-朴素贝叶斯" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/07/26/朴素贝叶斯/" class="article-date">
  <time datetime="2017-07-26T14:17:19.000Z" itemprop="datePublished">2017-07-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      朴素贝叶斯
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h4><pre><code>P(Y|X) = P(X|Y)P(Y)/P(X)
P(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y)
P(&apos;属于某类&apos; | &apos;具有某特征&apos;)
</code></pre><p>只需要找到一些包含已知特征标签的样本，即可训练。</p>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p>贝叶斯的核心思想：高概率对应的类别。<br></p>
<p>如果    P(‘属于A类’| ‘具有某特征’) &gt; P(‘属于B类’| ‘具有某特征’)，那么(x,y)属于A类。</p>
<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><ul>
<li>分词：把一句话拆成更细粒度的词语来。</li>
<li>停用词(stop words)：无助于我们分类的词。</li>
<li>词袋子模型(bag of words): 贝叶斯失去了词语之间的顺序信息。</li>
<li>朴素贝叶斯: 加上条件独立假设的贝叶斯方法 </li>
</ul>
<h3 id="使用python进行文本分类"><a href="#使用python进行文本分类" class="headerlink" title="使用python进行文本分类"></a>使用python进行文本分类</h3><a id="more"></a>
<p>思路过程：</p>
<ol>
<li>拆分文本： 对文本集合进行分词,去掉标点符号、数字、停用词等特征预处理</li>
<li>考虑所有词汇： 选取部分词汇集合</li>
<li>区分好训练集和测试集</li>
<li>对训练集 将文本向量转换成数字向量 [0,1,1,0,0]</li>
<li>训练算法：计算概率 [0,1/2,1/2,0,0]</li>
<li>对测试集 文本向量转换成数字向量</li>
<li>P(X|Yi)P(Yi) 向量相乘，对比概率大小</li>
<li>分类结果与测试集对比，求出错误率</li>
</ol>
<p>伪代码：</p>
<pre><code>计算每个类别中的文档数目
对每篇训练文档
    对每个类别
        如果词条出现在文档中-&gt;增加该词条的计数
        增加所有词条的数值
对每个类别
    各词条的数目／所有词条数 -&gt;条件概率
返回每个类别的条件概率(和各词条在某类中出现的概率)
</code></pre><h3 id="代码分解"><a href="#代码分解" class="headerlink" title="代码分解"></a>代码分解</h3><p>样本</p>
<pre><code>def loadDataSet():
    postingList = [[&apos;my&apos;, &apos;dog&apos;, &apos;has&apos;, &apos;flea&apos;, &apos;problems&apos;, &apos;help&apos;, &apos;please&apos;],
               [&apos;maybe&apos;, &apos;not&apos;, &apos;take&apos;, &apos;him&apos;, &apos;to&apos;, &apos;dog&apos;, &apos;park&apos;, &apos;stupid&apos;],
               [&apos;my&apos;, &apos;dalmation&apos;, &apos;is&apos;, &apos;so&apos;, &apos;cute&apos;, &apos;I&apos;, &apos;love&apos;, &apos;him&apos;],
               [&apos;stop&apos;, &apos;posting&apos;, &apos;stupid&apos;, &apos;worthless&apos;, &apos;garbage&apos;],
               [&apos;mr&apos;, &apos;licks&apos;, &apos;ate&apos;, &apos;my&apos;, &apos;steak&apos;, &apos;how&apos;, &apos;to&apos;, &apos;stop&apos;, &apos;him&apos;],
               [&apos;quit&apos;, &apos;buying&apos;, &apos;worthless&apos;, &apos;dog&apos;, &apos;food&apos;, &apos;stupid&apos;]]
    classVec = [0,1,0,1,0,1]
    return postingList,classVec
</code></pre><p>分词</p>
<pre><code>def testParse(bigString):
    # 去掉单词、数字，字符串长度小于2
    lisetOfToken = re.split(&apos;\\W*&apos;, bigString)
    # 全部小写处理
    return [tok.lower() for tok in lisetOfToken if len(tok) &gt; 2]
</code></pre><p>取得所有词汇</p>
<pre><code>def creatVocabList(dataSet):
    vocabSet = set([])
    for document in dataSet:
        vocabSet = vocabSet | set(document)
    return vocabSet
</code></pre><p>取出前三十个高频字符串，去掉 (with and you for之类)    </p>
<pre><code>#vocabList 所有词汇  fullText未去重过的词汇
def calcMostFreq(vocabList, fullText):
    freqDict = {}
    for token in vocabList:
        freqDict[token] = fullText.count(token)
    # iteritems 排序
    sortedFreq = sorted(freqDict.items(), key=operator.itemgetter(1),\
                reverse=True)
    return sortedFreq[:30]
</code></pre><p>留存交叉验证： (随机取20个作为测试集 其他为训练集)</p>
<pre><code>trainingSet = list(range(2 * minLen)); testSet = []
for i in range(20):
    randIndex = int(np.random.uniform(0, len(trainingSet)))
    testSet.append(trainingSet[randIndex])    
    del(trainingSet[randIndex])
</code></pre><p>训练模型－词量模型:不计算重复词语出现的次数</p>
<pre><code>def setOfWords2Vec(vocabList, inputSet):
    returnVet = [1 if w in inputSet else 0 for w in vocabList]
    return returnVet
</code></pre><p>训练模型－词袋模型:计算重复词语出现的次数                </p>
<pre><code>def bagOfWords2VecMN(vocabList, inputSet):
    returnVet = [0] * len(vocabList)
    for i in range(len(vocabList)):
        if vocabList[i] in inputSet:
            returnVet[i] += 1
    return returnVet    
</code></pre><p>训练算法<br>注：</p>
<ol>
<li>想求函数的最大值时,可以使用该函数的自然对数来替换原函数进行求解</li>
<li>平滑处理：将所有词的出现数初始化为1,所有词条数初始化为2</li>
</ol>
<pre><code>
# 训练算法：从词向量计算概率
# trainMatrix：文档矩阵(数字向量)
# trainCategory：文档对应的类别 0正常 1垃圾

def trainNB0(trainMatrix, trainCategory):
    # 文档数量
    numTrainDocs = len(trainMatrix)
    # 词汇量大小
    numWords = len(trainMatrix[0])
    # 垃圾文档的概率
    pAbusive = sum(trainCategory)/float(numTrainDocs)
    # 创建一个全部为0的矩阵p0Num
    # [1,2,3,4,0,0,1]即第一个词在垃圾文档中出现的次数1次，第二个出现2次
    # p1Denom 所有的词出现的总数 即1+2+3+4+1=11
    p0Num = np.ones(numWords); p1Num = np.ones(numWords)
    p0Denom = 2.0; p1Denom = 2.0

    for i in range(numTrainDocs):
        if trainCategory[i] == 1:
            p1Num += trainMatrix[i]
            p1Denom += sum(trainMatrix[i])
        else:
            p0Num += trainMatrix[i]
            p0Denom += sum(trainMatrix[i])
    # 得到每个词在垃圾文档中出现的频率[1/11,2/11,3/11,4/11,0,0,1/11]    
    p1Vect = [math.log(x/p1Denom) for x in p1Num]
    p0Vect = [math.log(x/p0Denom) for x in p0Num]
    # p1Vect = p1Num/p1Denom
    # p0Vect = p0Num/p0Denom
    return p1Vect,p0Vect,pAbusive
</code></pre><p>朴素贝叶斯分类函数</p>
<pre><code>def classifyNB(vec2Classify, p0Vect,p1Vect,pClass1):
    p1VecSum = 0; p0VecSum = 0
    for i in range(len(p0Vect)):
        p1VecSum += vec2Classify[i] * p1Vect[i]
        p0VecSum += vec2Classify[i] * p0Vect[i]

    p1 = p1VecSum + math.log(pClass1)
    p0 = p0VecSum + math.log(1.0 - pClass1)
    # p1 = sum(vec2Classify * p1Vect) + math.log(pClass1)
    # p0 = sum(vec2Classify * p0Vect) + math.log(1.0 - pClass1)
    if p1 &gt; p0:
        return 1
    else:
        return 0
</code></pre><h3 id="示例：使用naive-bayes从个人广告中获取区域倾向"><a href="#示例：使用naive-bayes从个人广告中获取区域倾向" class="headerlink" title="示例：使用naive bayes从个人广告中获取区域倾向"></a>示例：使用naive bayes从个人广告中获取区域倾向</h3><p>训练出模型后，获取各分类 词条出现概率较高的前十个单词    </p>
<pre><code># -*- coding: utf-8 -*-
# !/usr/bin/env python

import feedparser
import re
import words2vec as bayes
import numpy as np
import operator    

def testParse(bigString):
    # 去掉单词、数字，字符串长度小于2
    lisetOfToken = re.split(&apos;\\W*&apos;, bigString)
    # 全部小写处理
    return [tok.lower() for tok in lisetOfToken if len(tok) &gt; 2]

# 取出前三十个高频字符串   with and you for之类
def calcMostFreq(vocabList, fullText):
    freqDict = {}
    for token in vocabList:
        freqDict[token] = fullText.count(token)
    # iteritems 排序
    sortedFreq = sorted(freqDict.items(), key=operator.itemgetter(1),\
                    reverse=True)
    return sortedFreq[:50]                    

def localWords(feed1, feed0):
    docList = []; classList = []; fullText = []
    minLen = min(len(feed1[&apos;entries&apos;]), len(feed0[&apos;entries&apos;]))
    # print(minLen)
    for i in range(minLen):
        wordList = testParse(feed1[&apos;entries&apos;][i][&apos;summary&apos;])
        docList.append(wordList)
        fullText.extend(wordList)
        classList.append(1)
        wordList = testParse(feed0[&apos;entries&apos;][i][&apos;summary&apos;])
        docList.append(wordList)
        fullText.extend(wordList)
        classList.append(0)
    # 创建所有 词向量
    vocabList = bayes.creatVocabList(docList)
    # 取出前三十个高频字符串
    top30Words = calcMostFreq(vocabList, fullText)
    # print(top30Words)
    # 去掉高频词
    for pairW in top30Words:
        if pairW[0] in vocabList:
            vocabList.remove(pairW[0])
    print(vocabList)
    print(len(vocabList))        
    # 留存交叉验证     随机取20个作为测试集 其他为训练集
    trainingSet = list(range(2 * minLen)); testSet = []
    for i in range(20):
        randIndex = int(np.random.uniform(0, len(trainingSet)))
        testSet.append(trainingSet[randIndex])    
        del(trainingSet[randIndex])
    # print(testSet)
    # 训练模型
    trainMat = []; trainClasses = []
    for docIndex in trainingSet:
        trainMat.append(bayes.bagOfWords2VecMN(list(vocabList),docList[docIndex]))
        trainClasses.append(classList[docIndex])
    p0V,p1V,pSpam = bayes.trainNB0(np.array(trainMat), np.array(trainClasses))
    # print(&apos;pSpam: &apos;,pSpam)
    # 测试数据 查看错误率
    errorCount = 0
    for docIndex in testSet:
        wordVector = bayes.bagOfWords2VecMN(list(vocabList),docList[docIndex])
        if bayes.classifyNB(wordVector,p0V,p1V,pSpam) != classList[docIndex]:
            errorCount += 1
            # print(docList[docIndex], &apos;error&apos;)
    print(&apos;the error rate is: &apos;, float(errorCount)/len(testSet))    
    return vocabList,p0V,p1V    

def getTopWords(ny,sf):
    vocabList,p0V,p1V = localWords(ny,sf)
    topNY = []; topSF = []
    for i in range(len(p0V)):
        if p0V[i] &gt; -6.0:    
            topSF.append((list(vocabList)[i],p0V[i]))
        if p1V[i] &gt; -6.0:
            topNY.append((list(vocabList)[i],p1V[i]))

    sortedSF = sorted(topSF, key=lambda pair: pair[1], reverse=True)
    print(&apos;SF *****   *****    *****&apos;)
    top10SF = map(lambda x: x[0], sortedSF[:10])
    for i in top10SF:
        print(i)

    sortedNY = sorted(topNY, key=lambda pair: pair[1], reverse=True)
    print(&apos;NY *****   *****    *****&apos;)
    for item in sortedNY[:10]:
        print(item[0])

if __name__ == &apos;__main__&apos;:
    ny = feedparser.parse(&apos;http://newyork.craigslist.org/stp/index.rss&apos;)
    sf = feedparser.parse(&apos;http://sfbay.craigslist.org/stp/index.rss&apos;)
    getTopWords(ny,sf)
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/07/26/朴素贝叶斯/" data-id="cjpp94qvy001s2yluo1y5hy68" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/naive-bayes/">naive bayes</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/07/27/Bag-of-Words-Meets-Bags-of-Popcorn/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          Bag-of-Words-Meets-Bags-of-Popcorn
        
      </div>
    </a>
  
  
    <a href="/2016/01/27/strtok分割时间/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">strtok与sscanf</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELK/">ELK</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Elasticsearch/">Elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Logistic/">Logistic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knn/">knn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/">math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/naive-bayes/">naive bayes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/recommend/">recommend</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrape/">scrape</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spider/">spider</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 10px;">C</a> <a href="/tags/ELK/" style="font-size: 10px;">ELK</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Logistic/" style="font-size: 10px;">Logistic</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/knn/" style="font-size: 20px;">knn</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/naive-bayes/" style="font-size: 15px;">naive bayes</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/recommend/" style="font-size: 10px;">recommend</a> <a href="/tags/scrape/" style="font-size: 10px;">scrape</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/spider/" style="font-size: 10px;">spider</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/15/ELK日志系统入门/">ELK日志系统入门</a>
          </li>
        
          <li>
            <a href="/2018/09/14/selenium-PhantomJs爬虫/">selenium+PhantomJs爬虫</a>
          </li>
        
          <li>
            <a href="/2018/09/14/spark读取hive数据-java/">spark读取hive数据-java</a>
          </li>
        
          <li>
            <a href="/2018/09/13/elasticsearch时间柱状图聚合java实现/">elasticsearch时间柱状图聚合java实现</a>
          </li>
        
          <li>
            <a href="/2018/04/10/爬取航班数据/">爬取航班数据</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 pangrou<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="https://github.com/pangrou" class="mobile-nav-link">GitHub</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>