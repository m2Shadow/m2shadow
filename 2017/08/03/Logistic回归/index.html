<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Logistic回归 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="《机器学习实战》 回归概念：假设有一些数据点，我们用一条直线对这些点进行拟合，这个拟合过程成为回归。这条线称之为 最佳拟合直线。 主要思想：根据现有数据对分类边界线建立回归公式，以此进行分类。 “回归”一词源于最佳拟合，表示要找到最佳拟合参数集。     Sigmoid函数f(x) = 1/(1 + e(-x)) 当 x = 0时, f(x) = 0; 随着 x 的增大，f(x) 逼近于1；随着">
<meta name="keywords" content="Logistic">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic回归">
<meta property="og:url" content="http://yoursite.com/2017/08/03/Logistic回归/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="《机器学习实战》 回归概念：假设有一些数据点，我们用一条直线对这些点进行拟合，这个拟合过程成为回归。这条线称之为 最佳拟合直线。 主要思想：根据现有数据对分类边界线建立回归公式，以此进行分类。 “回归”一词源于最佳拟合，表示要找到最佳拟合参数集。     Sigmoid函数f(x) = 1/(1 + e(-x)) 当 x = 0时, f(x) = 0; 随着 x 的增大，f(x) 逼近于1；随着">
<meta property="og:updated_time" content="2017-08-04T06:31:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Logistic回归">
<meta name="twitter:description" content="《机器学习实战》 回归概念：假设有一些数据点，我们用一条直线对这些点进行拟合，这个拟合过程成为回归。这条线称之为 最佳拟合直线。 主要思想：根据现有数据对分类边界线建立回归公式，以此进行分类。 “回归”一词源于最佳拟合，表示要找到最佳拟合参数集。     Sigmoid函数f(x) = 1/(1 + e(-x)) 当 x = 0时, f(x) = 0; 随着 x 的增大，f(x) 逼近于1；随着">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-66782234-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="https://github.com/pangrou">GitHub</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Logistic回归" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/03/Logistic回归/" class="article-date">
  <time datetime="2017-08-03T10:49:56.000Z" itemprop="datePublished">2017-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Logistic回归
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>《机器学习实战》</p>
<h4 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h4><p>概念：假设有一些数据点，我们用一条直线对这些点进行拟合，这个拟合过程成为回归。这条线称之为 最佳拟合直线。<br></p>
<p>主要思想：根据现有数据对分类边界线建立回归公式，以此进行分类。<br></p>
<p>“回归”一词源于最佳拟合，表示要找到最佳拟合参数集。    <br></p>
<h4 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h4><pre><code>f(x) = 1/(1 + e(-x))
</code></pre><p>当 x = 0时, f(x) = 0; 随着 x 的增大，f(x) 逼近于1；随着 x 的减小，f(x) 逼近于0。<br></p>
<h3 id="2-Logistic回归分类器原理："><a href="#2-Logistic回归分类器原理：" class="headerlink" title="2.Logistic回归分类器原理："></a>2.Logistic回归分类器原理：</h3><p>  我们可以在每个特征上都乘以一个回归系数，然后把所有的结果值相加，将这个总和代入Sigmoid函数中，进而得到一个0～1之间的数值。 任何大于0.5的数据被分为1类，小于0.5则被归为0类。 所以，Logistic回归也可以被看成是一种概率估计。<br><a id="more"></a></p>
<h3 id="3-基于最优化方法的最佳回归系数确定"><a href="#3-基于最优化方法的最佳回归系数确定" class="headerlink" title="3.基于最优化方法的最佳回归系数确定"></a>3.基于最优化方法的最佳回归系数确定</h3><p>  Sigmoid函数 输入记为Z,</p>
<pre><code>Z = wOx0 + w1x1 + w2x2 + ... + wNxN 
</code></pre><p>  可以写成    Z = wTx, 表示将这两个数值向量对应元素相乘然后全部加起来。 其中，x是分类器的输入参数，w就是最佳回归系数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def Sigmoid(inX):</div><div class="line">	return 1.0/(1+math.exp(-inX))</div></pre></td></tr></table></figure>
<h3 id="梯度上升算法"><a href="#梯度上升算法" class="headerlink" title="梯度上升算法"></a>梯度上升算法</h3><p>我们需要寻找合适的参数 w 使得 wTx = 0 成为很好的分类判定边界。<br><br>思想：<br><br>要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。<br><br>对于Logistic回归而言，损失函数为非凸函数。重新定义损失函数后得到梯度上升算法迭代公式。</p>
<h3 id="梯度上升算法伪代码"><a href="#梯度上升算法伪代码" class="headerlink" title="梯度上升算法伪代码"></a>梯度上升算法伪代码</h3><p>每个回归系数初始化为1<br>重复r次：<br>    计算整个数据集的梯度<br>    使用 alpha * gradient 更新回归系数<br>返回回归系数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">weights = np.ones((n,1))</div><div class="line">	for k in range(maxCycles):</div><div class="line">		h = sigmoid(np.dot(dataMatrix,weights))</div><div class="line">		error = labelMat - h</div><div class="line">		weights = weights + alpha*dataMatrix.transpose()*error</div><div class="line">	return weights</div></pre></td></tr></table></figure>
<h3 id="Logistic回归-梯度上升优化算法"><a href="#Logistic回归-梯度上升优化算法" class="headerlink" title="Logistic回归 梯度上升优化算法"></a>Logistic回归 梯度上升优化算法</h3><p>1.读取数据并提取对应的类别标签</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def loadDataSet():</div><div class="line">	dataMat = []; labelMat = []</div><div class="line">	for line in open(&apos;data/testSet.txt&apos;).readlines():</div><div class="line">		lineArr = line.strip().split()</div><div class="line">		dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])</div><div class="line">		labelMat.append(int(lineArr[2]))</div><div class="line">	return dataMat,labelMat</div></pre></td></tr></table></figure>
<ol>
<li>sigmoid函数和梯度上升的程序</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">def sigmoid(inX):</div><div class="line">	return 1.0/(1+math.exp(-inX))</div><div class="line"></div><div class="line">def gradAscent(dataMatIn, classLabels):</div><div class="line">	dataMatrix = np.mat(dataMatIn)</div><div class="line">	labelMat = np.mat(classLabels).transpose()</div><div class="line">	m,n = np.shape(dataMatIn)</div><div class="line">	alpha = 0.001</div><div class="line">	maxCycles = 500</div><div class="line">	weights = np.ones((n,1))</div><div class="line">	for k in range(maxCycles):</div><div class="line">		h = sigmoid(np.dot(dataMatrix,weights))</div><div class="line">		error = labelMat - h</div><div class="line">		weights = weights + alpha*dataMatrix.transpose()*error</div><div class="line">	return weights</div></pre></td></tr></table></figure>
<p>得到的结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  logistic git:(master) ✗ python logistic.py</div><div class="line">[[ 4.12414349]</div><div class="line"> [ 0.48007329]</div><div class="line"> [-0.6168482 ]]</div></pre></td></tr></table></figure>
<p>3.分析数据：画出决策边界</p>
<p>对于hθ(x)=g(θTx)而言，θTx &gt; 0,y = 1;θTx &lt; 0, y = 0.所以我们认为θTx = 0是一个决策边界。<br></p>
<p>hθ(x)=g(θ0+θ1X1+θ2X2) <br><br>-&gt; θ0+θ1X1+θ2X2 = 0 <br><br>-&gt; x2 = (-θ0-θ1X1)/θ2 <br><br>-&gt; y = (-θ0-θ1X)/θ2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">def plotBestFit(weights,dataMat,labelMat):</div><div class="line">	dataArr = np.mat(dataMat)</div><div class="line">	weights = weights.getA()</div><div class="line">	n = np.shape(dataArr)[0]</div><div class="line">	xcord1 = []; ycord1 = []</div><div class="line">	xcord2 = []; ycord2 = []</div><div class="line">	for i in range(n):</div><div class="line">		if int(labelMat[i]) == 1:</div><div class="line">			xcord1.append(dataArr[i,1])</div><div class="line">			ycord1.append(dataArr[i,2])</div><div class="line">		else:</div><div class="line">			xcord2.append(dataArr[i,1])</div><div class="line">			ycord2.append(dataArr[i,2])</div><div class="line">	fig = plt.figure()</div><div class="line">	ax = fig.add_subplot(111)</div><div class="line">	ax.scatter(xcord1, ycord1, s=30, c=&apos;red&apos;, marker=&apos;s&apos;)</div><div class="line">	ax.scatter(xcord2, ycord2, s=30, c=&apos;green&apos;)</div><div class="line">	x = np.arange(-3.0, 3.0, 0.1)</div><div class="line">	y = (-weights[0] - weights[1]*x)/weights[2]	</div><div class="line">	ax.plot(x, y)</div><div class="line">	plt.xlabel(&apos;X1&apos;); plt.ylabel(&apos;X2&apos;)</div><div class="line">	plt.show()</div></pre></td></tr></table></figure>
<h3 id="随机梯度上升"><a href="#随机梯度上升" class="headerlink" title="随机梯度上升"></a>随机梯度上升</h3><p>梯度上升算法在每次更新回归系数时都需要遍历整个数据集，计算复杂度较高。<br><br>改进方法是 一次仅用一个样本点来更新回归系数。该方法称为随机梯度上升算法。<br></p>
<p>伪代码：<br><br>所有回归系数初始化为1<br>对数据集的每个样本：<br>    计算该样本的梯度<br>    使用 alpha * gradient 更新回归系数<br>返回回归系数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">def socGradAscent0(dataMatrix, classLabels):</div><div class="line">	m,n = np.shape(dataMatrix)</div><div class="line">	alpha = 0.01</div><div class="line">	weights = np.ones(n)</div><div class="line">	for i in range(m):</div><div class="line">		h = sigmoid(sum(dataMatrix[i]*weights))</div><div class="line">		error = classLabels[i] - h</div><div class="line">		weights = weights + alpha * dataMatrix[i] * error</div><div class="line">	return weights</div></pre></td></tr></table></figure>
<p>判断一个优化算法是否可靠的方式是看它是否收敛，也就是说参数是否达到了稳定值。 <br><br>通过改变该算法的迭代次数可以看出：某些特征的回归系数会有周期性波动。<br><br>这是因为数据集中存在一些不能正确分类的样本点，在每次迭代时会引发系数的剧烈波动。 <br></p>
<h3 id="改进的随机梯度上升算法"><a href="#改进的随机梯度上升算法" class="headerlink" title="改进的随机梯度上升算法"></a>改进的随机梯度上升算法</h3><p>为了解决随机梯度上升的问题，对算法进行了一些改进。<br></p>
<ol>
<li>alpha 在每次迭代时进行调整(随着迭代次数不断减小)</li>
<li>随机选取样本来更新回归系数</li>
<li>增加迭代次数</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">def socGradAscent1(dataMatrix, classLabels, numIter = 2):</div><div class="line">	m,n = np.shape(dataMatrix)</div><div class="line">	weights = np.ones(n)</div><div class="line">	for j in range(numIter):</div><div class="line">		dataIndex = list(range(m))</div><div class="line">		for i in range(m):</div><div class="line">			alpha = 0.04/(1.0+j+i) + 0.001</div><div class="line">			randIndex = int(np.random.uniform(0, len(dataIndex)))</div><div class="line">			h = sigmoid(sum(dataMatrix[randIndex]*weights))</div><div class="line">			error = classLabels[randIndex] - h</div><div class="line">			weights = weights + alpha * error * dataMatrix[randIndex]</div><div class="line">			del(dataIndex[randIndex])</div><div class="line">	return weights</div></pre></td></tr></table></figure>
<h3 id="示例：-从疝气病症预测病马的死亡率"><a href="#示例：-从疝气病症预测病马的死亡率" class="headerlink" title="示例： 从疝气病症预测病马的死亡率"></a>示例： 从疝气病症预测病马的死亡率</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"># -*- coding: utf-8 -*-</div><div class="line"># !/usr/bin/env python</div><div class="line"></div><div class="line">import logistic </div><div class="line">import numpy as np</div><div class="line"></div><div class="line">TRAIN_TIMES = 500</div><div class="line"></div><div class="line">def classifyVector(inX, weights):</div><div class="line">	prob = logistic.socSigmoid(sum(inX * weights))</div><div class="line">	if prob &gt;= 0.5:</div><div class="line">		return 1.0</div><div class="line">	else:</div><div class="line">		return 0.0</div><div class="line"></div><div class="line">def colicTest():</div><div class="line">	trainingSet = []; trainingLabels = []</div><div class="line">	for line in open(&apos;data/horseColicTraining.txt&apos;).readlines():</div><div class="line">		currLine = line.strip().split(&apos;\t&apos;)</div><div class="line">		lineArr = []</div><div class="line">		for i in range(len(currLine)-1):</div><div class="line">			lineArr.append(float(currLine[i]))</div><div class="line">		trainingSet.append(lineArr)	</div><div class="line">		trainingLabels.append(float(currLine[len(currLine)-1]))</div><div class="line">	weights = logistic.socGradAscent1(np.array(trainingSet),trainingLabels,TRAIN_TIMES)</div><div class="line">	# print(weights)</div><div class="line">	errorCount = 0; numTestVec = 0.0</div><div class="line">	for line in open(&apos;data/horseColicTest.txt&apos;).readlines():</div><div class="line">		numTestVec += 1.0</div><div class="line">		currLine = line.strip().split(&apos;\t&apos;)</div><div class="line">		lineArr = []</div><div class="line">		for i in range(len(currLine)-1):</div><div class="line">			lineArr.append(float(currLine[i]))</div><div class="line">		if int(classifyVector(lineArr,weights) != int(currLine[len(currLine)-1])):</div><div class="line">			errorCount += 1</div><div class="line">	# print(errorCount,numTestVec)</div><div class="line">	errorRate = float(errorCount)/numTestVec</div><div class="line">	print(&apos;the error rate of this test is :%f&apos; % errorRate)</div><div class="line">	return errorRate</div><div class="line"></div><div class="line">def multiTest():</div><div class="line">	numTests = 10; errorSum = 0.0</div><div class="line">	for k in range(numTests):</div><div class="line">		errorSum += colicTest()</div><div class="line">	print(&apos;after %d iterations the average error rate is :%f&apos; % (numTests,errorSum/float(numTests)))		</div><div class="line"></div><div class="line"></div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">	multiTest()</div></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/03/Logistic回归/" data-id="cjpp94quo000a2yluxhoduijo" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Logistic/">Logistic</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/08/18/TensorFlow实现自编码器/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          TensorFlow实现自编码器
        
      </div>
    </a>
  
  
    <a href="/2017/07/27/Bag-of-Words-Meets-Bags-of-Popcorn/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">Bag-of-Words-Meets-Bags-of-Popcorn</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELK/">ELK</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Elasticsearch/">Elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Logistic/">Logistic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knn/">knn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/">math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/naive-bayes/">naive bayes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/recommend/">recommend</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scrape/">scrape</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spider/">spider</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/C/" style="font-size: 10px;">C</a> <a href="/tags/ELK/" style="font-size: 10px;">ELK</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Logistic/" style="font-size: 10px;">Logistic</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/knn/" style="font-size: 20px;">knn</a> <a href="/tags/math/" style="font-size: 10px;">math</a> <a href="/tags/naive-bayes/" style="font-size: 15px;">naive bayes</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/recommend/" style="font-size: 10px;">recommend</a> <a href="/tags/scrape/" style="font-size: 10px;">scrape</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/spider/" style="font-size: 10px;">spider</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/15/ELK日志系统入门/">ELK日志系统入门</a>
          </li>
        
          <li>
            <a href="/2018/09/14/selenium-PhantomJs爬虫/">selenium+PhantomJs爬虫</a>
          </li>
        
          <li>
            <a href="/2018/09/14/spark读取hive数据-java/">spark读取hive数据-java</a>
          </li>
        
          <li>
            <a href="/2018/09/13/elasticsearch时间柱状图聚合java实现/">elasticsearch时间柱状图聚合java实现</a>
          </li>
        
          <li>
            <a href="/2018/04/10/爬取航班数据/">爬取航班数据</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 pangrou<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="https://github.com/pangrou" class="mobile-nav-link">GitHub</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>